{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import load_train_index\n",
    "from pathlib import Path\n",
    "from hw_asr.base.base_text_encoder import BaseTextEncoder\n",
    "\n",
    "VOCAB_SIZE = 500\n",
    "\n",
    "index_directory = Path('pretrained_model/index/')\n",
    "\n",
    "tokenizer_directory = Path('pretrained_model/tokenizer')\n",
    "tokenizer_directory.mkdir(exist_ok=True)\n",
    "texts_directory = tokenizer_directory / 'texts.txt'\n",
    "model_directory = tokenizer_directory / f'sentence_piece_vocab_{VOCAB_SIZE}'\n",
    "\n",
    "datasets = load_train_index(index_directory)\n",
    "\n",
    "sentences = []\n",
    "for dataset in datasets:\n",
    "    for observation in dataset:\n",
    "        sentences.append(BaseTextEncoder.normalize_text(observation['text']))\n",
    "with open(texts_directory, 'w') as f:\n",
    "    print(*sentences, sep='\\n', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "model_prefix = f'sentence_piece_vocab_{VOCAB_SIZE}'\n",
    "model_prefix = tokenizer_directory / model_prefix\n",
    "\n",
    "\n",
    "if not model_prefix.with_suffix('.model').exists():\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=texts_directory,\n",
    "        model_prefix=model_prefix,\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        model_type='bpe'\n",
    "    )\n",
    "sp_model = spm.SentencePieceProcessor(model_file=str(model_prefix) + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sp_model.unk_id() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it had no ornamentation being exceedingly plain in appearance'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it|had|no|or|n|am|ent|ation|be|ing|ex|ce|ed|ing|ly|pl|ain|in|app|e|ar|ance\n"
     ]
    }
   ],
   "source": [
    "encoded = sp_model.Encode('it had no ornamentation being exceedingly plain in appearance')\n",
    "print('|'.join([sp_model.IdToPiece(c).replace('‚ñÅ', '') for c in encoded]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = sp_model.Decode([sp_model.unk_id()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 33.,  39., 478., 205.,  57., 361., 308.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello world every day'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import reload\n",
    "reload('hw_asr')\n",
    "from hw_asr.text_encoder.ctc_char_bpe_encoder import CTCCharBpeEncoder  # noqa\n",
    "\n",
    "VOCAB_SIZE = 500\n",
    "\n",
    "encoder = CTCCharBpeEncoder(f'pretrained_model/tokenizer/sentence_piece_vocab_{VOCAB_SIZE}')\n",
    "encoded = encoder.encode('hello world every day')\n",
    "print(encoded)\n",
    "encoder.ctc_decode_enhanced(encoded[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "checkpoint = torch.load('pretrained_model/model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mambaforge\\envs\\cuda_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hw_asr.model.deep_speech import DeepSpeech2\n",
    "\n",
    "\n",
    "model = DeepSpeech2(n_feats=128, n_class=28)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "model.fc = nn.Linear(1024, VOCAB_SIZE, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "with open('hw_asr\\configs\\deep_speech_2_server_bpe.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "torch.save({\n",
    "    'state_dict': model.state_dict(),\n",
    "    'monitor_best': 0,\n",
    "    'config': config\n",
    "}, 'tmp/bpe_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
