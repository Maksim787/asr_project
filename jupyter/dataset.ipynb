{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "from hw_asr.base.base_text_encoder import BaseTextEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_directory = Path('saved_server/index/')\n",
    "assert index_directory.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_by_dataset = {}\n",
    "for path in index_directory.iterdir():\n",
    "    with open(path, 'r') as f:\n",
    "        observations_by_dataset[path.name.removesuffix('_index.json')] = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>max_audio_len</th>\n",
       "      <th>audio_len_99%</th>\n",
       "      <th>audio_len_95%</th>\n",
       "      <th>max_text_len</th>\n",
       "      <th>max_text_len_99%</th>\n",
       "      <th>max_text_len_95%</th>\n",
       "      <th>n_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dev-clean</th>\n",
       "      <td>2703</td>\n",
       "      <td>32.645</td>\n",
       "      <td>23.755</td>\n",
       "      <td>16.4135</td>\n",
       "      <td>516</td>\n",
       "      <td>366.96</td>\n",
       "      <td>256.9</td>\n",
       "      <td>5.387811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev-other</th>\n",
       "      <td>2864</td>\n",
       "      <td>35.155</td>\n",
       "      <td>22.17955</td>\n",
       "      <td>15.02925</td>\n",
       "      <td>427</td>\n",
       "      <td>307.48</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.121185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-clean</th>\n",
       "      <td>2620</td>\n",
       "      <td>34.955</td>\n",
       "      <td>25.47575</td>\n",
       "      <td>17.842</td>\n",
       "      <td>576</td>\n",
       "      <td>363.05</td>\n",
       "      <td>261.0</td>\n",
       "      <td>5.403467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test-other</th>\n",
       "      <td>2939</td>\n",
       "      <td>34.51</td>\n",
       "      <td>21.4248</td>\n",
       "      <td>15.761</td>\n",
       "      <td>618</td>\n",
       "      <td>320.24</td>\n",
       "      <td>226.0</td>\n",
       "      <td>5.341547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train-clean-100</th>\n",
       "      <td>28539</td>\n",
       "      <td>24.525</td>\n",
       "      <td>16.7031</td>\n",
       "      <td>16.085</td>\n",
       "      <td>398</td>\n",
       "      <td>289.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>100.59088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train-clean-360</th>\n",
       "      <td>104014</td>\n",
       "      <td>29.735</td>\n",
       "      <td>16.67</td>\n",
       "      <td>16.075</td>\n",
       "      <td>524</td>\n",
       "      <td>289.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>363.605608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train-other-500</th>\n",
       "      <td>148688</td>\n",
       "      <td>27.92</td>\n",
       "      <td>16.685</td>\n",
       "      <td>16.06</td>\n",
       "      <td>453</td>\n",
       "      <td>285.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>496.85791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                n_samples max_audio_len audio_len_99% audio_len_95%  \\\n",
       "dev-clean            2703        32.645        23.755       16.4135   \n",
       "dev-other            2864        35.155      22.17955      15.02925   \n",
       "test-clean           2620        34.955      25.47575        17.842   \n",
       "test-other           2939         34.51       21.4248        15.761   \n",
       "train-clean-100     28539        24.525       16.7031        16.085   \n",
       "train-clean-360    104014        29.735         16.67        16.075   \n",
       "train-other-500    148688         27.92        16.685         16.06   \n",
       "\n",
       "                max_text_len max_text_len_99% max_text_len_95%     n_hours  \n",
       "dev-clean                516           366.96            256.9    5.387811  \n",
       "dev-other                427           307.48            219.0    5.121185  \n",
       "test-clean               576           363.05            261.0    5.403467  \n",
       "test-other               618           320.24            226.0    5.341547  \n",
       "train-clean-100          398            289.0            262.0   100.59088  \n",
       "train-clean-360          524            289.0            264.0  363.605608  \n",
       "train-other-500          453            285.0            258.0   496.85791  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = [99, 95]\n",
    "df = pd.DataFrame(columns=(\n",
    "    ['n_samples', 'max_audio_len'] + \n",
    "    [f'audio_len_{q_i}%' for q_i in q] + \n",
    "    ['max_text_len'] +\n",
    "    [f'max_text_len_{q_i}%' for q_i in q] +\n",
    "    ['n_hours']\n",
    "))\n",
    "\n",
    "for name, ind in observations_by_dataset.items():\n",
    "    n_samples = len(ind)\n",
    "\n",
    "    audio_len = [x['audio_len'] for x in ind]\n",
    "    max_audio_len = max(audio_len)\n",
    "\n",
    "    text_len = [len(x['text']) for x in ind]\n",
    "    max_text_len = max(text_len)\n",
    "\n",
    "    df.loc[name, :] = (\n",
    "        [n_samples, max(audio_len)] +\n",
    "        [np.quantile(audio_len, q=q_i/100) for q_i in q] +\n",
    "        [max(text_len)] +\n",
    "        [np.quantile(text_len, q=q_i/100) for q_i in q] +\n",
    "        [sum(audio_len) / 60 / 60]\n",
    "    )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_index(ind: list[dict]):\n",
    "    cnt = Counter()\n",
    "    for observation in ind:\n",
    "        cnt.update(BaseTextEncoder.normalize_text(observation['text']).split())\n",
    "    return cnt\n",
    "\n",
    "\n",
    "words_by_dataset = {name: get_words_from_index(observations) for name, observations in observations_by_dataset.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = [name for name in observations_by_dataset if 'train' in name]\n",
    "val_names = [name for name in observations_by_dataset if 'dev' in name]\n",
    "test_names = [name for name in observations_by_dataset if 'test' in name]\n",
    "assert sorted(train_names + val_names + test_names) == sorted(observations_by_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_train = sum([words_by_dataset[name] for name in train_names], start=Counter())\n",
    "words_in_val = sum([words_by_dataset[name] for name in val_names], start=Counter())\n",
    "words_in_test = sum([words_by_dataset[name] for name in test_names], start=Counter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['train', 'val', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unique_words</th>\n",
       "      <td>86599</td>\n",
       "      <td>11739</td>\n",
       "      <td>11836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_words</th>\n",
       "      <td>9403555</td>\n",
       "      <td>105350</td>\n",
       "      <td>104919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                train     val    test\n",
       "unique_words    86599   11739   11836\n",
       "total_words   9403555  105350  104919"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['unique_words', :] = len(words_in_train), len(words_in_val), len(words_in_test)\n",
    "df.loc['total_words', :] = sum(words_in_train.values()), sum(words_in_val.values()), sum(words_in_test.values())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in test: 517\n",
      "Unique words in test count: 711 (0.6777%)\n"
     ]
    }
   ],
   "source": [
    "unique_test_words = set(words_in_test) - set(words_in_train) - set(words_in_val)\n",
    "print(f'Number of unique words in test: {len(unique_test_words)}')\n",
    "unique_test_words_count = sum([words_in_test[word] for word in unique_test_words])\n",
    "print(f'Unique words in test count: {unique_test_words_count} ({unique_test_words_count / df.loc[\"total_words\", \"test\"] * 100:.4f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dictionary(words_in_train: Counter, words_in_val: Counter):\n",
    "    spell = SpellChecker()\n",
    "    spell.word_frequency.remove_words(spell.word_frequency.dictionary)\n",
    "    words = []\n",
    "    for word, count in chain(words_in_train.items(), words_in_val.items()):\n",
    "        words += [word]  * count\n",
    "    spell.word_frequency.load_words(words)\n",
    "    assert spell.word_frequency.unique_words == len(set(words_in_train) | set(words_in_val))\n",
    "    return spell\n",
    "\n",
    "\n",
    "def correct(text: str, spell: SpellChecker):\n",
    "    result = []\n",
    "    for word in text.split():\n",
    "        corrected = spell.correction(word)\n",
    "        if corrected:\n",
    "            result.append(corrected)\n",
    "        else:\n",
    "            result.append(word)\n",
    "    return ' '.join(result)\n",
    "\n",
    "\n",
    "spell = build_dictionary(words_in_train, words_in_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test-clean', 'test-other'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_directory = Path('saved_server/output/')\n",
    "assert predictions_directory.exists()\n",
    "predictions = {}\n",
    "for path in predictions_directory.iterdir():\n",
    "    with open(path, 'r') as f:\n",
    "        predictions[f'{path.name.removesuffix(\"_output.json\")}'] = json.load(f)\n",
    "predictions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2620/2620 [07:37<00:00,  5.73it/s]\n",
      "100%|██████████| 2939/2939 [13:34<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "test-clean\n",
      "                                   WER       CER\n",
      "pred_text_argmax             14.286005  4.347183\n",
      "pred_text_beam_search        13.994843   4.25308\n",
      "pred_text_corrected_my       12.204572   4.31496\n",
      "pred_text_corrected_library  13.407942  4.859289\n",
      "==========\n",
      "==========\n",
      "test-other\n",
      "                                   WER        CER\n",
      "pred_text_argmax             31.420353  11.985951\n",
      "pred_text_beam_search        30.795859  11.682252\n",
      "pred_text_corrected_my       27.821106  11.995854\n",
      "pred_text_corrected_library  28.315971  12.566642\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "from hw_asr.metric.utils import calc_cer, calc_wer\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def autocorrect_sentence(sentence):\n",
    "    blob = TextBlob(sentence)\n",
    "    corrected_sentence = blob.correct()\n",
    "    return str(corrected_sentence)\n",
    "\n",
    "\n",
    "def add_predictions(observation: dict[str, str]):\n",
    "    observation = observation.copy()\n",
    "    observation['pred_text_corrected_my'] = correct(observation['pred_text_beam_search'], spell)\n",
    "    observation['pred_text_corrected_library'] = autocorrect_sentence(observation['pred_text_beam_search'])\n",
    "    return observation\n",
    "\n",
    "\n",
    "def compute_metrics(predictions: dict[str, list[dict[str, str]]]) -> dict[str, dict[str, dict[str, float]]]:\n",
    "    metrics_by_part = {}\n",
    "    for part, observations in predictions.items():\n",
    "        metrics = {'WER': defaultdict(list), 'CER': defaultdict(list)}\n",
    "        for observation in tqdm(observations):\n",
    "            observation = add_predictions(observation)\n",
    "            ground_truth = observation['ground_truth']\n",
    "            for name, prediction in observation.items():\n",
    "                if name != 'ground_truth':\n",
    "                    for metric, func in zip(['WER', 'CER'], [calc_wer, calc_cer]):\n",
    "                        metrics[metric][name].append(func(ground_truth, prediction) * 100)\n",
    "                        metrics[metric][name].append(func(ground_truth, prediction) * 100)\n",
    "        metrics_by_part[part] = {\n",
    "            metric: {\n",
    "                name: np.array(values).mean() for name, values in metric_by_predictions.items()\n",
    "            } for metric, metric_by_predictions in metrics.items()\n",
    "        }\n",
    "    return metrics_by_part\n",
    "\n",
    "\n",
    "def print_metrics(metrics: dict[str, dict[str, dict[str, float]]]):\n",
    "    for part, metrics_by_part in metrics.items():\n",
    "        print('=' * 10)\n",
    "        print(part)\n",
    "        df = pd.DataFrame(columns=metrics_by_part.keys())\n",
    "        for metric_name, metric_by_predictions in metrics_by_part.items():\n",
    "            for predictions_name, metric_value in metric_by_predictions.items():\n",
    "                df.loc[predictions_name, metric_name] = metric_value\n",
    "        print(df)\n",
    "        print('=' * 10)\n",
    "\n",
    "\n",
    "metrics = compute_metrics(predictions)\n",
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
